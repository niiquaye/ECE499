{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF\n",
    "\n",
    "## NerF-LiDAR: Generating Realistic LiDAR Point Clouds with Neural Radiance Fields\n",
    "\n",
    " >Labelling LiDAR point clouds for training autonomous driv\n",
    "ing is extremely expensive and difficult. LiDAR simulation\n",
    " aims at generating realistic LiDAR data with labels for train\n",
    "ing and verifying self-driving algorithms more efficiently. Re\n",
    "cently, Neural Radiance Fields (NeRF) have been proposed\n",
    " for novel view synthesis using implicit reconstruction of 3D\n",
    " scenes. Inspired by this, we present NeRF-LIDAR, a novel\n",
    " LiDAR simulation method that leverages real-world infor\n",
    "mation to generate realistic LIDAR point clouds. Different\n",
    " from existing LiDAR simulators, we use real images and\n",
    " point cloud data collected by self-driving cars to learn the 3D\n",
    " scene representation, point cloud generation and label ren\n",
    "dering. We verify the effectiveness of our NeRF-LiDAR by\n",
    " training different 3D segmentation models on the generated\n",
    " LiDAR point clouds. It reveals that the trained models are\n",
    " able to achieve similar accuracy when compared with the\n",
    " same model trained on the real LiDAR data. Besides, the\n",
    " generated data is capable of boosting the accuracy through\n",
    " pre-training which helps reduce the requirements of the real\n",
    " labeled data. Code is available at https://github.com/fudanzvg/NeRF-LiDAR\n",
    "\n",
    "## LiDAR-NeRF: Novel LiDAR View Synthesis via Neural Radiance Fields\n",
    "\n",
    " >Abstract: We introduce a new task, novel view synthesis for LiDAR sensors.\n",
    " While traditional model-based LiDAR simulators with style-transfer neural net\n",
    "works can be applied to render novel views, they fall short of producing accurate\n",
    " and realistic LiDAR patterns because the renderers rely on explicit 3D reconstruc\n",
    "tion and exploit game engines, that ignore important attributes of LiDAR points.\n",
    " We address this challenge by formulating, to the best of our knowledge, the first\n",
    " differentiable end-to-end LiDAR rendering framework, LiDAR-NeRF, leveraging\n",
    " a neural radiance field (NeRF) to facilitate the joint learning of geometry and the\n",
    " attributes of 3D points. However, simply employing NeRF cannot achieve satis\n",
    "factory results, as it only focuses on learning individual pixels while ignoring local\n",
    " information, especially at low texture areas, resulting in poor geometry. To this\n",
    " end, we have taken steps to address this issue by introducing a structural regular\n",
    "ization method to preserve local structural details. To evaluate the effectiveness of\n",
    " our approach, we establish an object-centric multi-view LiDAR dataset, dubbed\n",
    " NeRF-MVL. It contains observations of objects from 9 categories seen from 360\n",
    "degree viewpoints captured with multiple LiDAR sensors. Our extensive experi\n",
    "ments on the scene-level KITTI-360 dataset, and on our object-level NeRF-MVL\n",
    " show that our LiDAR-NeRF surpasses the model-based algorithms significantly.\n",
    " Our [project page](https://tangtaogo.github.io/lidar-nerf-website/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GS (Gaussian Splatting)\n",
    "\n",
    "## GS-LiDAR: Generating Realistic LiDAR Point Clouds With Panoramic Gaussian Splatting\n",
    "\n",
    "### Abstract\n",
    "\n",
    "\n",
    "> LiDAR novel view synthesis (NVS) has emerged as a novel task within LiDAR\n",
    " simulation, offering valuable simulated point cloud data from novel viewpoints\n",
    " to aid in autonomous driving systems. However, existing LiDAR NVS methods\n",
    " typically rely on neural radiance fields (NeRF) as their 3D representation, which\n",
    " incurs significant computational costs in both training and rendering. Moreover,\n",
    " NeRFandits variants are designed for symmetrical scenes, making them ill-suited\n",
    " for driving scenarios. To address these challenges, we propose GS-LiDAR, a novel\n",
    " framework for generating realistic LiDAR point clouds with panoramic Gaussian\n",
    " splatting. Our approach employs 2D Gaussian primitives with periodic vibration\n",
    " properties, allowing for precise geometric reconstruction of both static and dy\n",
    "namic elements in driving scenarios. We further introduce a novel panoramic ren\n",
    "dering technique with explicit ray-splat intersection, guided by panoramic LiDAR\n",
    " supervision. By incorporating intensity and ray-drop spherical harmonic (SH) co\n",
    "efficients into the Gaussian primitives, we enhance the realism of the rendered\n",
    " point clouds. Extensive experiments on KITTI-360 and nuScenes demonstrate the\n",
    " superiority of our method in terms of quantitative metrics, visual quality, as well\n",
    " as training and rendering efficiency https://github.com/fudan-zvg/GS-LiDAR\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GS-LiDAR vs NeRF\n",
    "\n",
    ">In recent years, neural radiance field (NeRF) (Mildenhall et al., 2020) has emerged as a foundational\n",
    " technique in the field of 3Dreconstruction. With its effective implicit representation and high-quality\n",
    " volumetric rendering, NeRF has been proposed as a novel approach for LiDAR simulation. NeRF\n",
    "LiDAR (Zhang et al., 2024) utilizes real images and LiDAR data to learn a Neural Radiance Field,\n",
    " generating point clouds and rendering semantic labels. On the other hand, LiDAR-NeRF (Tao et al.,\n",
    " >2023) introduces a novel LiDAR view synthesis task, which uses only LiDAR data as input to recon\n",
    "struct a 3D scene. However, LiDAR-NeRF is limited to modeling static scenes, whereas dynamic\n",
    " vehicles and pedestrians are common in driving scenarios. To address this, LiDAR4D (Zheng et al.,\n",
    " >2024) introduces a hybrid 4D representation for novel space-time LiDAR view synthesis. Although\n",
    " these NeRF-based methods mark significant progress compared to traditional techniques, they suf\n",
    "fer from slow training and rendering speeds, a limitation inherent to NeRF. Furthermore, efficient\n",
    " NeRF-based architectures like HashGrid (MÂ¨ uller et al., 2022), designed for symmetrical scenes, are\n",
    " not well-suited for driving scenarios.\n",
    "\n",
    "https://arxiv.org/pdf/2501.13971\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.neonscience.org/resources/learning-hub/tutorials/lidar-basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1612.00593v2 - deep learning for lidar data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NeRF to forest data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
